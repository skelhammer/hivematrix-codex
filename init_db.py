#!/usr/bin/env python3
"""
Codex Database Initialization and Migration Script

This script handles both initial setup and schema migrations for production deployments.

Features:
- Interactive database configuration setup
- Intelligent schema migrations (adds new columns without data loss)
- Safe for production use - preserves existing data
- Can be run multiple times safely (idempotent)

NOTE: PSA and Datto API keys should be configured through the Admin UI after database setup.

Usage:
    python init_db.py                    # Interactive setup
    python init_db.py --test             # Non-interactive: use defaults and test
    python init_db.py --migrate-only     # Skip config, just migrate schema
    python init_db.py --force-rebuild    # Nuclear option: drop and recreate (DEV ONLY)
"""

import os
import sys
import argparse
import configparser
import subprocess
from getpass import getpass
from sqlalchemy import create_engine, inspect, text
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import OperationalError
from dotenv import load_dotenv

load_dotenv('.flaskenv')
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# NOTE: We import app later in functions to allow config file to be created first
# For headless mode, app is imported AFTER config file is written
app = None
db = None

def _import_app():
    """Import app and db after config file exists."""
    global app, db
    if app is None:
        # Skip scheduler initialization and reduce logging during database setup
        os.environ['CODEX_SKIP_SCHEDULER'] = '1'
        os.environ['SERVICE_NAME'] = 'codex'  # Prevent "unknown service" log message

        # Suppress most logging during init
        import logging
        logging.getLogger('app').setLevel(logging.WARNING)
        logging.getLogger('app.scheduler').setLevel(logging.ERROR)

        from app import app as flask_app
        from extensions import db as database
        # Import ALL models so SQLAlchemy knows about them
        from models import (
            Company, Contact, Asset, CompanyFeatureOverride, Location,
            RMMSiteLink, TicketDetail, SyncJob, BillingPlan, FeatureOption, Agent
        )
        app = flask_app
        db = database
    return app, db


def get_db_credentials(config):
    """Prompts the user for PostgreSQL connection details."""
    print("\n--- PostgreSQL Database Configuration ---")

    db_details = {
        'host': 'localhost',
        'port': '5432',
        'user': 'codex_user',
        'dbname': 'codex_db'
    }

    # Load existing values if config exists
    if config.has_section('database_credentials'):
        db_details['host'] = config.get('database_credentials', 'db_host', fallback=db_details['host'])
        db_details['port'] = config.get('database_credentials', 'db_port', fallback=db_details['port'])
        db_details['dbname'] = config.get('database_credentials', 'db_name', fallback=db_details['dbname'])
        db_details['user'] = config.get('database_credentials', 'db_user', fallback=db_details['user'])

    host = input(f"Host [{db_details['host']}]: ") or db_details['host']
    port = input(f"Port [{db_details['port']}]: ") or db_details['port']
    dbname = input(f"Database Name [{db_details['dbname']}]: ") or db_details['dbname']
    user = input(f"User [{db_details['user']}]: ") or db_details['user']
    password = getpass("Password: ")

    return {
        'host': host,
        'port': port,
        'dbname': dbname,
        'user': user,
        'password': password
    }


def test_db_connection(creds):
    """Tests the database connection, automatically creating database if needed."""
    from urllib.parse import quote_plus

    # First check if database exists using psql (more reliable than SQLAlchemy connection attempt)
    check_cmd = f"sudo -u postgres psql -tAc \"SELECT 1 FROM pg_database WHERE datname='{creds['dbname']}'\""
    try:
        result = subprocess.run(check_cmd, shell=True, capture_output=True, text=True, timeout=5)
        db_exists = "1" in result.stdout
    except Exception:
        # If check fails, assume database doesn't exist and try to create it
        db_exists = False

    # Create database if it doesn't exist
    if not db_exists:
        print(f"\nâ†’ Database '{creds['dbname']}' does not exist. Creating it...")
        create_cmd = f"sudo -u postgres psql -c \"CREATE DATABASE {creds['dbname']} OWNER {creds['user']};\""
        try:
            result = subprocess.run(create_cmd, shell=True, capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                print(f"âœ“ Database '{creds['dbname']}' created successfully!")
            else:
                print(f"\nâœ— Failed to create database: {result.stderr}", file=sys.stderr)
                print(f"  You may need to create it manually:")
                print(f"  sudo -u postgres psql -c \"CREATE DATABASE {creds['dbname']} OWNER {creds['user']};\"")
                return None, False
        except Exception as e:
            print(f"\nâœ— Failed to create database: {e}", file=sys.stderr)
            return None, False

    # Now test connection
    escaped_password = quote_plus(creds['password'])
    conn_string = f"postgresql://{creds['user']}:{escaped_password}@{creds['host']}:{creds['port']}/{creds['dbname']}"

    try:
        engine = create_engine(conn_string)
        with engine.connect() as connection:
            print("\nâœ“ Database connection successful!")
            return conn_string, True
    except OperationalError as e:
        print(f"\nâœ— Connection failed: {e}", file=sys.stderr)
        return None, False




def migrate_schema():
    """
    Intelligently migrates database schema without losing data.

    This function:
    1. Inspects existing tables and columns
    2. Compares with models defined in models.py
    3. Adds missing columns (with defaults)
    4. Creates missing tables
    5. Does NOT drop columns or tables (safe for production)
    """
    print("\n" + "="*80)
    print("DATABASE SCHEMA MIGRATION")
    print("="*80)

    app, db = _import_app()
    with app.app_context():
        inspector = inspect(db.engine)
        existing_tables = inspector.get_table_names()

        print(f"\nFound {len(existing_tables)} existing tables in database")

        # Get all tables defined in models
        model_tables = db.metadata.tables

        # Track changes
        tables_created = []
        columns_added = []

        # Create tables in dependency order (association tables last)
        # First, create all base tables (no foreign keys to other app tables)
        base_tables = []
        association_tables = []

        for table_name, table in model_tables.items():
            # Association tables typically have multiple foreign keys and no primary key of their own
            # or have 'link' in the name
            if 'link' in table_name.lower() or len([c for c in table.columns if c.foreign_keys]) >= 2:
                association_tables.append((table_name, table))
            else:
                base_tables.append((table_name, table))

        # Create base tables first
        for table_name, table in base_tables:
            if table_name not in existing_tables:
                # Table doesn't exist - create it
                print(f"\nâ†’ Creating new table: {table_name}")
                table.create(db.engine)
                tables_created.append(table_name)
            else:
                # Table exists - check for missing columns (below)
                pass

        # Then create association tables
        for table_name, table in association_tables:
            if table_name not in existing_tables:
                # Table doesn't exist - create it
                print(f"\nâ†’ Creating new association table: {table_name}")
                table.create(db.engine)
                tables_created.append(table_name)
            else:
                # Table exists - check for missing columns (below)
                pass

        # Now check all tables for missing columns
        for table_name, table in base_tables + association_tables:
            if table_name in existing_tables:
                # Table exists - check for missing columns
                existing_columns = {col['name'] for col in inspector.get_columns(table_name)}
                model_columns = {col.name for col in table.columns}
                missing_columns = model_columns - existing_columns

                if missing_columns:
                    print(f"\nâ†’ Updating table '{table_name}' - adding {len(missing_columns)} columns:")

                    # Validate table name is a valid identifier
                    import re
                    if not re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', table_name):
                        print(f"   âœ— Invalid table name format: {table_name}")
                        continue

                    for col_name in missing_columns:
                        # Validate column name is a valid identifier
                        if not re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', col_name):
                            print(f"   âœ— Invalid column name format: {col_name}")
                            continue

                        col = table.columns[col_name]
                        col_type = col.type.compile(db.engine.dialect)

                        # Build ALTER TABLE statement
                        nullable = "NULL" if col.nullable else "NOT NULL"
                        default = ""

                        # Add default value if specified
                        if col.default is not None:
                            if hasattr(col.default, 'arg'):
                                # Column default (e.g., default=True)
                                default_val = col.default.arg
                                if isinstance(default_val, str):
                                    default = f"DEFAULT '{default_val}'"
                                elif isinstance(default_val, bool):
                                    default = f"DEFAULT {str(default_val).upper()}"
                                else:
                                    default = f"DEFAULT {default_val}"

                        # For NOT NULL columns without default, make them nullable for migration
                        if not col.nullable and not default:
                            nullable = "NULL"
                            print(f"   âš  Column '{col_name}' is NOT NULL but has no default - making nullable for safety")

                        # Use quoted identifiers for safety
                        sql = f'ALTER TABLE "{table_name}" ADD COLUMN "{col_name}" {col_type} {default} {nullable}'

                        try:
                            with db.engine.connect() as conn:
                                conn.execute(text(sql))
                                conn.commit()
                            print(f"   âœ“ Added column: {col_name} ({col_type})")
                            columns_added.append(f"{table_name}.{col_name}")
                        except Exception as e:
                            print(f"   âœ— Failed to add column {col_name}: {e}")

        # Summary
        print("\n" + "="*80)
        print("MIGRATION SUMMARY")
        print("="*80)

        if tables_created:
            print(f"\nâœ“ Created {len(tables_created)} new table(s):")
            for t in tables_created:
                print(f"  - {t}")
        else:
            print("\nâ€¢ No new tables created")

        if columns_added:
            print(f"\nâœ“ Added {len(columns_added)} new column(s):")
            for c in columns_added:
                print(f"  - {c}")
        else:
            print("\nâ€¢ No new columns added")

        if not tables_created and not columns_added:
            print("\nâœ“ Schema is up to date - no changes needed")

        print("\n" + "="*80)


def force_rebuild():
    """
    DANGEROUS: Drops all tables and recreates from scratch.
    Only use in development!
    """
    print("\n" + "!"*80)
    print("âš  WARNING: FORCE REBUILD MODE")
    print("!"*80)
    print("\nThis will DELETE ALL DATA in the database!")
    print("This should ONLY be used in development environments.")
    print("\nType 'DELETE ALL DATA' to confirm:")

    confirmation = input("> ")
    if confirmation != "DELETE ALL DATA":
        print("\nAborted.")
        sys.exit(0)

    app, db = _import_app()
    print("\nâ†’ Dropping all tables...")
    with app.app_context():
        db.drop_all()
        print("âœ“ All tables dropped")

        print("\nâ†’ Creating fresh schema...")
        db.create_all()
        print("âœ“ Schema recreated")

    print("\nâœ“ Force rebuild complete")



def init_db_headless(db_host, db_port, db_name, db_user, db_password, migrate_only=False, create_sample_data=False):
    """Non-interactive database initialization for automated installation."""
    from urllib.parse import quote_plus

    print("\n" + "="*80)
    print("CODEX DATABASE INITIALIZATION (HEADLESS MODE)")
    print("="*80)

    # Determine instance path without importing app yet
    script_dir = os.path.dirname(os.path.abspath(__file__))
    instance_path = os.path.join(script_dir, 'instance')
    config_path = os.path.join(instance_path, 'codex.conf')

    config = configparser.RawConfigParser()

    # Create or update config
    if os.path.exists(config_path):
        config.read(config_path)
        print(f"\nâœ“ Loaded existing configuration: {config_path}")
    else:
        print(f"\nâ†’ Creating new configuration: {config_path}")
        os.makedirs(instance_path, exist_ok=True)

    # Check if database exists, create if needed
    check_cmd = f"sudo -u postgres psql -tAc \"SELECT 1 FROM pg_database WHERE datname='{db_name}'\""
    try:
        result = subprocess.run(check_cmd, shell=True, capture_output=True, text=True, timeout=5)
        db_exists = "1" in result.stdout
    except Exception:
        db_exists = False

    if not db_exists:
        print(f"\nâ†’ Database '{db_name}' does not exist. Creating it...")
        create_cmd = f"sudo -u postgres psql -c \"CREATE DATABASE {db_name} OWNER {db_user};\""
        try:
            result = subprocess.run(create_cmd, shell=True, capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                print(f"âœ“ Database '{db_name}' created successfully!")
            else:
                print(f"âœ— Failed to create database: {result.stderr}", file=sys.stderr)
                sys.exit(1)
        except Exception as e:
            print(f"âœ— Failed to create database: {e}", file=sys.stderr)
            sys.exit(1)

    # Build connection string
    escaped_password = quote_plus(db_password)
    conn_string = f"postgresql://{db_user}:{escaped_password}@{db_host}:{db_port}/{db_name}"

    # Test connection
    print(f"\nâ†’ Testing database connection to {db_host}:{db_port}/{db_name}...")
    try:
        engine = create_engine(conn_string)
        with engine.connect() as connection:
            print("âœ“ Database connection successful")
    except Exception as e:
        print(f"âœ— Connection failed: {e}", file=sys.stderr)
        sys.exit(1)

    # Save configuration
    if not config.has_section('database'):
        config.add_section('database')
    config.set('database', 'connection_string', conn_string)

    if not config.has_section('database_credentials'):
        config.add_section('database_credentials')
    config.set('database_credentials', 'db_host', db_host)
    config.set('database_credentials', 'db_port', db_port)
    config.set('database_credentials', 'db_name', db_name)
    config.set('database_credentials', 'db_user', db_user)

    # Add default PSA configuration if not present
    if not config.has_section('psa'):
        config.add_section('psa')
        config.set('psa', 'default_provider', 'freshservice')

    # Add default RMM configuration if not present
    if not config.has_section('rmm'):
        config.add_section('rmm')
        config.set('rmm', 'default_provider', 'datto')

    # Add scheduler configuration if not present (vendor-neutral)
    if not config.has_section('scheduler'):
        config.add_section('scheduler')
        config.set('scheduler', 'sync_psa_enabled', 'true')
        config.set('scheduler', 'sync_rmm_enabled', 'true')
        config.set('scheduler', 'sync_tickets_enabled', 'true')
        config.set('scheduler', 'sync_psa_schedule', 'daily')
        config.set('scheduler', 'sync_rmm_schedule', 'daily')
        config.set('scheduler', 'sync_tickets_schedule', 'frequent')
        config.set('scheduler', 'sync_run_on_startup', 'false')

    # Note: PSA and RMM API keys should be configured through the Admin UI

    with open(config_path, 'w') as configfile:
        config.write(configfile)
    print(f"âœ“ Configuration saved to: {config_path}")

    # Run schema migration (app will be imported now and will read the config we just wrote)
    print("")
    migrate_schema()

    print("\n" + "="*80)
    print(" âœ“ Codex Initialization Complete!")
    print("="*80)


def init_db(migrate_only=False, force=False, test_mode=False):
    """Main initialization function."""
    print("\n" + "="*80)
    print("CODEX DATABASE INITIALIZATION")
    print("="*80)

    if force:
        force_rebuild()
        return

    app, db = _import_app()
    instance_path = app.instance_path
    config_path = os.path.join(instance_path, 'codex.conf')

    # Use RawConfigParser to avoid interpolation issues with special characters
    config = configparser.RawConfigParser()

    if test_mode:
        # Non-interactive test mode - use defaults and show errors
        print("\nâ†’ Running in TEST MODE (non-interactive)")

        # Read existing config if it exists to preserve PSA/Datto settings
        if os.path.exists(config_path):
            config.read(config_path)
            print(f"â†’ Loaded existing configuration from: {config_path}")

        print("Using default credentials:")

        # Generate random password for test mode
        import secrets
        import string
        alphabet = string.ascii_letters + string.digits
        test_password = ''.join(secrets.choice(alphabet) for _ in range(16))

        default_creds = {
            'host': 'localhost',
            'port': '5432',
            'dbname': 'codex_db',
            'user': 'codex_user',
            'password': test_password
        }

        print(f"  Host: {default_creds['host']}")
        print(f"  Port: {default_creds['port']}")
        print(f"  Database: {default_creds['dbname']}")
        print(f"  User: {default_creds['user']}")
        print(f"  Password: {'*' * len(default_creds['password'])}")

        print("\nTesting database connection...")
        conn_string, success = test_db_connection(default_creds)

        if success:
            print("\nâœ“ Connection test PASSED")
            print(f"âœ“ Connection string: {conn_string.replace(default_creds['password'], '***')}")

            # Save the config
            if not config.has_section('database'):
                config.add_section('database')
            config.set('database', 'connection_string', conn_string)

            if not config.has_section('database_credentials'):
                config.add_section('database_credentials')
            for key, val in default_creds.items():
                if key != 'password':
                    config.set('database_credentials', f'db_{key}', val)

            # Note: PSA and Datto API keys should be configured through the Admin UI
            # Save minimal config
            os.makedirs(instance_path, exist_ok=True)
            with open(config_path, 'w') as configfile:
                config.write(configfile)
            print(f"âœ“ Configuration saved to: {config_path}")

            # Run migration
            migrate_schema()
            print("\nâœ“ Test mode complete - database is ready!")
            return
        else:
            print("\nâœ— Connection test FAILED")
            print("Please check:")
            print("  1. PostgreSQL is running: sudo systemctl status postgresql")
            print("  2. User exists: sudo -u postgres psql -c \"\\du codex_user\"")
            print("  3. Database exists: sudo -u postgres psql -c \"\\l codex_db\"")
            print("  4. Password matches the test database configuration")
            sys.exit(1)

    if not migrate_only:
        config_exists = os.path.exists(config_path)
        if config_exists:
            config.read(config_path)
            print(f"\nâœ“ Existing configuration found: {config_path}")
            print("Press Enter to keep existing values, or type new values to update.")
        else:
            print(f"\nâ†’ No existing configuration found. Creating new config: {config_path}")

        # Database configuration
        conn_string = None
        while True:
            creds = get_db_credentials(config)
            conn_string, success = test_db_connection(creds)
            if success:
                if not config.has_section('database'):
                    config.add_section('database')
                config.set('database', 'connection_string', conn_string)

                if not config.has_section('database_credentials'):
                    config.add_section('database_credentials')
                for key, val in creds.items():
                    if key != 'password':  # Don't store password in plain text
                        config.set('database_credentials', f'db_{key}', val)
                break
            else:
                retry = input("\nWould you like to try again? (y/n): ").lower()
                if retry != 'y':
                    sys.exit("Database configuration aborted.")

        # Note: PSA and Datto API keys should be configured through the Admin UI
        # Save database configuration only
        with open(config_path, 'w') as configfile:
            config.write(configfile)

        print(f"\nâœ“ Configuration saved to: {config_path}")
    else:
        # Migrate-only mode: load existing config
        if os.path.exists(config_path):
            config.read(config_path)
            print(f"\nâœ“ Using existing configuration: {config_path}")
        else:
            print(f"\nâœ— No configuration found at {config_path}")
            print("Run without --migrate-only to create configuration first")
            sys.exit(1)

    # Run schema migration
    migrate_schema()

    print("\n" + "="*80)
    print(" ðŸŽ‰ Codex Initialization Complete!")
    print("="*80)
    print("\nIMPORTANT: Codex is the central data hub for HiveMatrix")
    print("  - Codex syncs from PSA & RMM systems")
    print("  - Ledger pulls billing data from Codex")
    print("  - KnowledgeTree pulls support context from Codex")
    print("="*80)
    print("\nNext steps:")
    print("  1. (Optional) Review configuration: instance/codex.conf")
    print("  2. Sync data from external systems (via Codex dashboard or CLI):")
    print("     â†’ python sync_psa.py --type all        # Companies, contacts, tickets")
    print("     â†’ python sync_rmm.py                   # Assets & backup data")
    print("  3. Start the Codex service:")
    print("     â†’ flask run --port=5010         # Development")
    print("     â†’ python run.py                 # Production (Waitress)")
    print("\n  Access at: http://localhost:5010")
    print("  (Login via Core/Nexus gateway)")
    print("="*80)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Initialize or migrate Codex database schema',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        '--migrate-only',
        action='store_true',
        help='Skip configuration, only run schema migration'
    )
    parser.add_argument(
        '--force-rebuild',
        action='store_true',
        help='DANGEROUS: Drop all tables and rebuild (DEV ONLY)'
    )
    parser.add_argument(
        '--test',
        action='store_true',
        help='Non-interactive mode: use defaults and test connection'
    )

    parser.add_argument(
        '--headless',
        action='store_true',
        help='Non-interactive mode for automated installation'
    )
    parser.add_argument(
        '--db-host',
        type=str,
        default='localhost',
        help='Database host (default: localhost)'
    )
    parser.add_argument(
        '--db-port',
        type=str,
        default='5432',
        help='Database port (default: 5432)'
    )
    parser.add_argument(
        '--db-name',
        type=str,
        default='codex_db',
        help='Database name (default: codex_db)'
    )
    parser.add_argument(
        '--db-user',
        type=str,
        default='codex_user',
        help='Database user (default: codex_user)'
    )
    parser.add_argument(
        '--db-password',
        type=str,
        help='Database password (required for headless mode)'
    )
    parser.add_argument(
        '--create-sample-data',
        action='store_true',
        help='Create sample data for new database (headless mode only)'
    )

    args = parser.parse_args()

    # Handle headless mode
    if args.headless:
        if not args.db_password:
            print("ERROR: --db-password is required for headless mode", file=sys.stderr)
            sys.exit(1)

        init_db_headless(
            db_host=args.db_host,
            db_port=args.db_port,
            db_name=args.db_name,
            db_user=args.db_user,
            db_password=args.db_password,
            migrate_only=args.migrate_only,
            create_sample_data=args.create_sample_data
        )
    else:
        init_db(migrate_only=args.migrate_only, force=args.force_rebuild, test_mode=args.test)
